[{"数据集名称":"fibona-1","question":"如何使用市场中的知识库?","expected_result":"在知识库聊天界面，点击右上角 **“市场”** 按钮即可进入知识库市场弹窗，在这里你可以对知识库进行点收藏，收藏后使用知识库进行聊天，并且在提示词时可供绑定。","prompt_id":"1085"},{"数据集名称":"fibona-2","question":"如何使用本地pdf文件新建知识库？","expected_result":"## Fibona知识库特点  在Fibona中，你可以将需要ai作为参考的内容传入知识库（支持txt、md、pdf文件与iwiki、cos链接），根据内容与格式进行相关选项的配置，如果你想要更进一步深入使用知识库，定制一些知识库的使用逻辑甚至联动其它模块，不妨创建一个绑定知识库的提示词，在这里能设置更多可能会让内容更符合你预期的选项，如果你对你所创建的知识库很满意，也可以将其分享给他人。更多细节请查看详细文档介绍：","prompt_id":"1085"},{"数据集名称":"fibona-3","question":"如何快速搭建知识库并绑定提示词？","expected_result":"## Fibona提示词  在Fibona中，提示词不仅可以绑定知识库，让ai回答时能参考你提供的知识库内容，还可以进行域名的绑定，详细使用方法请参考提示词创建指引","prompt_id":"1085"},{"数据集名称":"fibona-4","question":"如何分享自己的提示词呢?","expected_result":"# 提示词使用指引 1. 在fibona插件左下角，选择你要使用的模型(如果你的提示词未绑定模型) 2. 打开fibona插件，在快速使用可以看到(若你的提示词绑定了域名，则需要进入指定网页)，创建和收藏的提示词(Top3个)。点击左下角的魔法棒可以查看所有创建和收藏的提示词。 3. 点击要使用的提示词，如果提示词内有变量，则会弹出交互窗口，可以选择打字、粘贴、划词输入。（例如：有个翻译提示词里面的提示词变量为：1. 目标语言， 2. 要翻译的内容，则在使用的时候要分别在它们的文本框输入相应的内容）。 4. 如果创作出了效果极佳的提示词，不妨将其公开分享给其他人吧，只需在提示词编辑中将提示词由私有变成公共，即可在市场中看到你创建的提示词，随后点击市场中提示词边框内的分享按钮即可转发给他人。快快向ta分享吧！ 5. Enjoy it !","prompt_id":"1085"},{"数据集名称":"fibona-5","question":"提示词变量如何设置?","expected_result":"# 提示词使用指引  1. 在fibona插件左下角，选择你要使用的模型(如果你的提示词未绑定模型) 2. 打开fibona插件，在快速使用可以看到(若你的提示词绑定了域名，则需要进入指定网页)，创建和收藏的提示词(Top3个)。点击左下角的魔法棒可以查看所有创建和收藏的提示词。 3. 点击要使用的提示词，如果提示词内有变量，则会弹出交互窗口，可以选择打字、粘贴、划词输入。（例如：有个翻译提示词里面的提示词变量为：1. 目标语言， 2. 要翻译的内容，则在使用的时候要分别在它们的文本框输入相应的内容）。 4. 如果创作出了效果极佳的提示词，不妨将其公开分享给其他人吧，只需在提示词编辑中将提示词由私有变成公共，即可在市场中看到你创建的提示词，随后点击市场中提示词边框内的分享按钮即可转发给他人。快快向ta分享吧！ 5. Enjoy it !","prompt_id":"1085"},{"数据集名称":"drop-1","question":"进程 __debug_bin3480 中的线程 2464225 占比整体 81.52%、进程 100.0%。线程内 runtime.Stack.func1 函数占比 86.55%，Golang运行时获取GoID较多，建议替换获取GoID方式?","expected_result":"## 问题 6: zx-save 组件获取 goroutine ID 性能差        ### 问题分析                ev-save 组件 CPU 使用率变化非常剧烈，经分析，主要是 seelog Goid 函数性能较差导致，该函数调用 golang runtime.Stack（获取当前 goroutime 调用栈，操作比较重）。                ![image](https://iwiki.woa.com/tencent/api/attachments/s3/url?attachmentid=17349994)\\nCPU 100% 左右时，函数 git.woa.com/zhixinlian/websdk/requestid.Goid 占比 41.6%，里面调用了 golang runtime.Stack。                ![image](https://iwiki.woa.com/tencent/api/attachments/s3/url?attachmentid=17349995)                CPU 接近 400% 时，该函数占比 88.6%。                ![image](https://iwiki.woa.com/tencent/api/attachments/s3/url?attachmentid=17349997)\\n施加压力越大，ev-save 组件的性能越差。获取当前 goroutine ID 实现的性能较差，参考下另一种高效稳定的实现：        [plz/goid.go at master · v2pro/plz · GitHub](https://github.com/v2pro/plz/blob/master/gls/goid.go)        [获取Goroutine Id的最佳实践 - 简书](https://www.jianshu.com/p/85a08d8e7af3)        ### 优化方案实施                websdk 直接调用 [plz/goid.go](https://github.com/v2pro/plz/blob/master/gls/goid.go) GoID() 函数，替换 runtime.Stack 实现（commit: [up go id get](https://git.woa.com/zhixinlian/websdk/commit/21fac30c47a625cadd6970abc31147c61155577e)）。        go test 对比新旧两种方式，调用一百万次，旧的方式需要 4 秒多，新的 0.00s，差别很明显。                ![image](https://iwiki.woa.com/tencent/api/attachments/s3/url?attachmentid=17349999)\\n### 优化结果对比                #### user 组件                使用 nft buy 接口做了下对比，同等压力条件下：user 组件整体使用核数，从峰值 11.36 下降到 7.45，节省了 1/3 的 CPU 资源。TPS 从 1200 左右提升至 1336，平均延迟从 100 ms 左右降至 85 ms。                ![image](https://iwiki.woa.com/tencent/api/attachments/s3/url?attachmentid=17350002)\\n![image](https://iwiki.woa.com/tencent/api/attachments/s3/url?attachmentid=17350005)\\nGoid 性能问题消除，采样中已经没有了这个函数出现。                ![image](https://iwiki.woa.com/tencent/api/attachments/s3/url?attachmentid=17350007)                现有热点函数：        1. 第三方 cihub/seelog.(*asyncLoopLogger).processQueue 这个还在，采样占比 11.5%。        2. websdk seelog 相关函数已经从 40% 多的占比降为 5% 之内。        3. gc 采样占比（runtime.gcDrain）上升为 14%（处理请求更快了）        #### zx-kv 组件                Goid 对 zx-kv 组件的影响更大一些。整体 CPU 使用量从 15 ~ 17 核，降至 5 ~ 6 核。用更少的资源，但 TPS、请求延迟达标。                ![image](https://iwiki.woa.com/tencent/api/attachments/s3/url?attachmentid=17350008)\\n![image](https://iwiki.woa.com/tencent/api/attachments/s3/url?attachmentid=17350009)","prompt_id":"1099"},{"数据集名称":"drop-2","question":"ret会返回什么？","expected_result":"### def run(vms):\\\\n\\\\n  vm = vms[0]\\\\ncmd = 'bash \\\\{target\\\\} -r \\\\{batch_size\\\\} \\\\{batch_num\\\\}' \\\\n\\\\n    .format(target=SCRIPT_PATH, batch_size=flags.FLAGS.alexnet_batch_size, batch_num=flags.FLAGS.alexnet_batch_num)\\\\nproc = vm.call_asyn(cmd)\\\\nret = proc.wait(logging.info, logging.error, timeout=10000, logfile=True)# 异步获取结果，防止超时\\\\nassert ret.exitcode == 0, 'run alexnext failed'\\\\nlogging.info(\\\\\\\"accept bash recall:\\\\{\\\\}\\\\\\\".format(ret)) # 可从 ret.out获取命令内容  ret.exitcode执行码，正常结束为0  ret.err获取错误信息\\\\nresult = {}\\\\n# 进行结果的解析和处理\\\\n# ................\\\\nreturn results","prompt_id":"1200"},{"数据集名称":"drop-3","question":"__fill_random_buf 函数采样占比超过 5%(83%)，疑似性能瓶颈，请查看火焰图进一步分析。","expected_result":"## 解决方案\\n### 参数 scramble_buffers 替代 refill_buffers\\n\\n![image.png](https://iwiki.woa.com/tencent/api/attachments/s3/url?attachmentid=18428930)\\nscramble_buffers 作用：轻微扰动下 buffer 内容，比 refill_buffer 每个字节都重新计算填充代价应该小很多，也可以有效阻止数据压缩。\\nscramble_buffers 原理：按每个 512 Byte 随机，注释也提到了防止容易数据压缩的情况（prevent too easy compressible data for simple de-dupe）\\n![image.png](https://iwiki.woa.com/tencent/api/attachments/s3/url?attachmentid=18428934)\\n开启参数 scramble_buffers 时，CPU 使用率仅增加了 10% 左右。\\n\\nrefill_buffers=1：\\n\\n\\n\\n\\nCPU 100%\\nscramble_buffers=1：\\n\\n\\n\\nCPU ~60%\\nrefill_buffers=0 & scramble_buffers=0:   CPU ~50%\\n\\nfio 文档也提到了这一点：\\n\\nIf refill_buffers is too costly and the target is using data deduplication, then setting this option will slightly modify the I/O buffer contents to defeat normal de-dupe attempts. This is not enough to defeat more clever block compression attempts, but it will stop naive dedupe of blocks.\\n\\n![image.png](https://iwiki.woa.com/tencent/api/attachments/s3/url?attachmentid=18428936)\\nhttps://fio.readthedocs.io/en/latest/fio_doc.html#cmdoption-arg-refill_buffers\\n 采用参数 --scramble_buffers 代替 --refill_buffers，既可以保持提交数据一定程度的随机性，也可以把写带宽打满（10G/s)。\\n![image.png](https://iwiki.woa.com/tencent/api/attachments/s3/url?attachmentid=18428938)\\n## fio 相关源码\\n\\nhttps://fio.readthedocs.io/en/latest/fio_doc.html#cmdoption-arg-refill_buffers\\n https://fio.readthedocs.io/en/latest/fio_doc.html#cmdoption-arg-scramble_buffers\\n https://github.com/axboe/fio/blob/fio-3.14/io_u.c#L1723\\n https://github.com/axboe/fio/blob/fio-3.14/lib/rand.c#L98","prompt_id":"1099"},{"数据集名称":"性能问题-1","question":"我遇到 all2all 问题，我可以采取什么思路分析问题？","expected_result":"For every resource, check utilization, saturation, and errors.  对于每个资源，检查利用率、饱和度和错误。","prompt_id":"1348"},{"数据集名称":"性能问题-2","question":"为什么只有 All2All 带宽性能会受到影响？","expected_result":" 由对 all2all 的分析，对涉及的通信操作进行测试，仅 scatter 带宽存在劣化，由代码实现结合可知，劣化仅在单 rank 向多 rank 进行 send 操作时会出现。","prompt_id":"1348"},{"数据集名称":"性能问题-3","question":"P2P 对集合通信的带宽的影响是怎么样的？","expected_result":"对 P2P 及其适应程度进行观测，发现随着 P2P 连接越少， all2all 和 scatter 操作带宽越正常的现象。  完全禁用时，带宽正常。","prompt_id":"1348"},{"数据集名称":"性能问题-4","question":"如果问题使用前后对比观测的手段进行分析，可以收集的指标有什么？","expected_result":"ER1：  对 scatter 不同卡数带宽进行测试，发现 3 卡后带宽骤降，与结合 GPU0，1 与 2，3 之间的拓扑关系，确定当通过QPI跨NUMA node间GPU通信(只能通过系统互联，即CPU和主内存)设备 > 2 时出现异常。  ER2:  使用 perf 进行 IOMMU 的事件进行采集，对比后无明显结论。  ER3:  在母机上采集前后 CPU 利用率，无差异。","prompt_id":"1348"},{"数据集名称":"性能问题-5","question":"All2All 有相关联的集合通信原语吗？","expected_result":"All to All为全交换操作，通过All to All通信，可以让每个节点都获取其他节点的值。Alltoall通信结合了scatter和gather的功能。","prompt_id":"1348"},{"数据集名称":"性能问题-6","question":"PCIE 有关事件可以用什么工具采集？","expected_result":"AMD软件性能分析工具，包含多元采集工具，本问题主要是使用其进行了 PCIE 带宽及 Events 计数观测。","prompt_id":"1348"},{"数据集名称":"性能问题-7","question":"All2All 的代码底层实现是什么？","expected_result":"在 NCCL 中，scatter ，gather 和 all2all 共用两个关键函数实现：ncclSend 和 ncclRecv。","prompt_id":"1348"},{"数据集名称":"性能问题-8","question":"为什么仅在 P2P 开启时出现问题？","expected_result":"使用 SYS 时，all2all ，scatter 劣化至最小水平。卡间通信带宽随着 p2p 连接的增多而降低。","prompt_id":"1348"},{"数据集名称":"性能问题-9","question":"为什么同 NODE 下 GPU 拓扑还是 SYS 而不是 PHB？","expected_result":"由此，首先对 GPU 拓扑进行观测：  [root@host_30_221_140_229 ~]# nvidia-smi topo -mp          GPU0    GPU1    GPU2    GPU3    GPU4    GPU5    GPU6    GPU7    CPU Affinity    NUMA Affinity   GPU NUMA ID  GPU0     X      SYS     SYS     SYS     SYS     SYS     SYS     SYS     0-95,192-287    0               N/A  GPU1    SYS      X      PHB     SYS     SYS     SYS     SYS     SYS     0-95,192-287    0               N/A  GPU2    SYS     PHB      X      SYS     SYS     SYS     SYS     SYS     0-95,192-287    0               N/A  GPU3    SYS     SYS     SYS      X      SYS     SYS     SYS     SYS     0-95,192-287    0               N/A  GPU4    SYS     SYS     SYS     SYS      X      SYS     SYS     SYS     96-191,288-383  1               N/A  GPU5    SYS     SYS     SYS     SYS     SYS      X      PHB     SYS     96-191,288-383  1               N/A  GPU6    SYS     SYS     SYS     SYS     SYS     PHB      X      SYS     96-191,288-383  1               N/A  GPU7    SYS     SYS     SYS     SYS     SYS     SYS     SYS      X      96-191,288-383  1               N/A","prompt_id":"1348"},{"数据集名称":"性能问题-10","question":"既然只能通过系统互连（即CPU和主内存），为什么还能 P2P?","expected_result":"由此，首先对 GPU 拓扑进行观测：  [root@host_30_221_140_229 ~]# nvidia-smi topo -mp          GPU0    GPU1    GPU2    GPU3    GPU4    GPU5    GPU6    GPU7    CPU Affinity    NUMA Affinity   GPU NUMA ID  GPU0     X      SYS     SYS     SYS     SYS     SYS     SYS     SYS     0-95,192-287    0               N/A  GPU1    SYS      X      PHB     SYS     SYS     SYS     SYS     SYS     0-95,192-287    0               N/A  GPU2    SYS     PHB      X      SYS     SYS     SYS     SYS     SYS     0-95,192-287    0               N/A  GPU3    SYS     SYS     SYS      X      SYS     SYS     SYS     SYS     0-95,192-287    0               N/A  GPU4    SYS     SYS     SYS     SYS      X      SYS     SYS     SYS     96-191,288-383  1               N/A  GPU5    SYS     SYS     SYS     SYS     SYS      X      PHB     SYS     96-191,288-383  1               N/A  GPU6    SYS     SYS     SYS     SYS     SYS     PHB      X      SYS     96-191,288-383  1               N/A  GPU7    SYS     SYS     SYS     SYS     SYS     SYS     SYS      X      96-191,288-383  1               N/A  发现 GPU1，2、5，6 一组形成同一Root complex下的数据传输路线，其余形成跨NUMA node间GPU通信。","prompt_id":"1348"},{"数据集名称":"性能问题-11","question":"为什么只有 scatter 出现问题？","expected_result":"由对 all2all 的分析，对涉及的通信操作进行测试，仅 scatter 带宽存在劣化，由代码实现结合可知，劣化仅在单 rank 向多 rank 进行 send 操作时会出现。","prompt_id":"1348"},{"数据集名称":"性能问题-12","question":"IOM 及其他结构的作用？","expected_result":"CPU 内不同结构使用不同时钟的传输链路。IO 0~3 连接不同 PICE bus。","prompt_id":"1348"}]